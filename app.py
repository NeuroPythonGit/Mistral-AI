# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import sounddevice as sd  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—É–¥–∏–æ-—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏
import numpy as np  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–∞—Å—Å–∏–≤–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
import wave  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å WAV —Ñ–∞–π–ª–∞–º–∏
import time  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–µ–º
import os  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
from scipy.io import wavfile  # –î–ª—è –∑–∞–ø–∏—Å–∏ –∏ —á—Ç–µ–Ω–∏—è WAV —Ñ–∞–π–ª–æ–≤
from faster_whisper import WhisperModel  # –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ
from gtts import gTTS  # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Google Text-to-Speech
import gradio as gr  # –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
import asyncio  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
from concurrent.futures import ThreadPoolExecutor  # –î–ª—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
from mistral_client import MistralClient  # –î–ª—è —Ä–∞–±–æ—Ç—ã —Å Mistral AI (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤)
from dotenv import load_dotenv  # –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Mistral API, –∏—Å–ø–æ–ª—å–∑—É—è API-–∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
mistral_client = MistralClient(api_key=os.getenv("MISTRAL_API_KEY"))

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ
model = WhisperModel("base", device="cpu", compute_type="int8")

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
class VoiceAssistant:
    def __init__(self):
        self.recording = False  # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∑–∞–ø–∏—Å–∏
        self.audio_data = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
        self.sample_rate = 44100  # –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ
        self.executor = ThreadPoolExecutor(max_workers=1)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω –ø–æ—Ç–æ–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á

    # –ú–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    def check_microphone(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ä–∞–±–æ—Ç–∞—é—â–µ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        try:
            devices = sd.query_devices()  # –ó–∞–ø—Ä–æ—Å —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
            input_devices = [d for d in devices if d['max_input_channels'] > 0]  # –í—ã–±–∏—Ä–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –≤–≤–æ–¥
            if not input_devices:
                return "No input devices found!"  # –ï—Å–ª–∏ –Ω–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è –≤–≤–æ–¥–∞, –≤—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            
            device_list = "\nAvailable input devices:\n"  # –°—Ç—Ä–æ–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
            for d in input_devices:
                device_list += f"- {d['name']}\n"  # –î–æ–±–∞–≤–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤ —Å–ø–∏—Å–æ–∫
            default_device = sd.query_devices(kind='input')  # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            device_list += f"\nUsing default input device: {default_device['name']}"  # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
            return device_list
        except Exception as e:
            return f"Error checking microphone: {e}"  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞
    async def process_voice(self, audio_data, sample_rate):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ –∏–∑ Gradio"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            wavfile.write("temp.wav", sample_rate, audio_data)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç
            text = self.transcribe_audio()
            if not text:
                return "Failed to transcribe audio", None  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò
            response = await self.get_ai_response(text)
            if not response:
                return "Failed to get AI response", None  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å —Å –ø–æ–º–æ—â—å—é gTTS
            try:
                print("Generating audio response...")
                tts = gTTS(text=response, lang='ru')  # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
                tts.save("temp_response.wav")  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç –≤ —Ñ–∞–π–ª
                
                return f"You: {text}\nAssistant: {response}", "temp_response.wav"  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –ø—É—Ç—å –∫ –∞—É–¥–∏–æ
            except Exception as e:
                return f"Error in speech generation: {e}", None  # –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏
                
        except Exception as e:
            return f"Error processing voice: {e}", None  # –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–∞

    # –ú–µ—Ç–æ–¥ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ Whisper
    def transcribe_audio(self, filename="temp.wav"):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Whisper"""
        try:
            segments, info = model.transcribe(filename, beam_size=5)  # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
            transcribed_text = " ".join([segment.text for segment in segments])  # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            return transcribed_text
        except Exception as e:
            print(f"Error during transcription: {e}")  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            return None

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Mistral
    async def get_ai_response(self, text):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò —Å –ø–æ–º–æ—â—å—é Mistral AI"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å –ò–ò
            messages = [
                {"role": "system", "content": "You are a helpful voice assistant. Keep your responses concise and natural."},
                {"role": "user", "content": text}
            ]
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Mistral API
            response = await mistral_client.chat_completion(
                messages=messages,
                model="mistral-small-latest"
            )
            return response  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –ò–ò
        except Exception as e:
            print(f"Error getting AI response: {e}")  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —Å –ø–æ–º–æ—â—å—é Gradio
def create_gradio_interface():
    assistant = VoiceAssistant()  # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    
    with gr.Blocks(title="Voice Assistant") as interface:  # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –ø–æ–º–æ—â—å—é Gradio
        gr.Markdown("# üéôÔ∏è Voice Assistant with gTTS")  # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        
        with gr.Row():  # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É
            with gr.Column():  # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É
                mic_info = gr.Textbox(  # –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–µ
                    value=assistant.check_microphone(),
                    label="Microphone Status",
                    interactive=False  # –¢–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è
                )
                
        with gr.Row():  # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É
            audio_input = gr.Audio(  # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                sources=["microphone"],
                type="numpy",  # –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–≤–æ–¥–∞
                label="Speak here"
            )
            
        with gr.Row():  # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É
            output_text = gr.Textbox(label="Conversation")  # –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            output_audio = gr.Audio(label="Assistant's Response")  # –ü–æ–ª–µ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç–∞
            
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ-–≤—Ö–æ–¥–∞
        audio_input.change(
            fn=lambda x: asyncio.run(assistant.process_voice(x[1], x[0])),  # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–æ–ª–æ—Å
            inputs=[audio_input],  # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî –∞—É–¥–∏–æ
            outputs=[output_text, output_audio]  # –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ
        )
        
    return interface  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

# –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã
if __name__ == "__main__":  
    interface = create_gradio_interface()  # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    interface.launch(share=True)  # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
